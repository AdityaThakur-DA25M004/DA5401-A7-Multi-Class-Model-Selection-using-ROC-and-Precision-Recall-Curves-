# DA5401 Assignment-7: Multi-Class Model Selection using ROC & Precision-Recall Curves

#### Name: Aditya Thakur &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Roll No: DA25M004

This project implements and analyzes multiple machine learning models for **multi-class satellite land-cover classification** using the **UCI Landsat Satellite dataset**.  
The focus is on **threshold-based model evaluation** using:

- âœ… Multi-Class ROC Curves (OvR)
- âœ… Multi-Class Precisionâ€“Recall Curves (OvR)
- âœ… Weighted AUC & Average Precision (AP)
- âœ… Weighted F1-Score & Accuracy

The assignment applies both **baseline classical ML models** and **ensemble models** for bonus points, identifies a **model performing worse than random**, and recommends the **best performing model** for deployment.

---

## ðŸŽ¯ Learning Objectives

| Task | Skill Demonstrated |
|---|---|
Data preparation | Clean dataset, verify splits |
Baseline modeling | Six classical models |
Evaluation | Accuracy, weighted-F1, ROC-AUC (OvR), PR-AUC |
Curve interpretation | ROC & PR insights |
Model tuning | RF & XGBoost |
Failure case | Model with AUC < 0.5 |

---

## ðŸ“Š Dataset â€” UCI Landsat Satellite

- 6 land-cover classes
- Moderate imbalance (classes 1, 3, 7 dominant)
- Multispectral continuous features

---

## âœ… Part A â€” Data Preparation & Baseline Performance

### âœ” Models Trained
| Model | Purpose |
|---|---|
Dummy Classifier | Baseline |
Logistic Regression | Linear model |
KNN | Distance-based |
Decision Tree | Interpretable baseline |
Gaussian NB | Probabilistic baseline |
SVC | Kernel decision model |

### ðŸŽ¯ Baseline Results
| Model | Accuracy | Weighted-F1 | Notes |
|---|---|---|---|
Dummy | ~0.23 | ~0.09 | Majority class |
Naive Bayes | ~0.80 | ~0.80 | Independence assumption |
Logistic Regression | ~0.83 | ~0.82 | Strong linear baseline |
Decision Tree | ~0.85 | ~0.86 | High variance |
KNN | ~0.90 | ~0.90 | Top baseline |
SVC | ~0.90 | ~0.89 | Most stable |

---

## ðŸ§  Part B â€” Multi-Class ROC-AUC (OvR)

| Model | Macro AUC | Notes |
|---|---|---|
SVC | ~0.985 | Best separation |
KNN | ~0.979 | Very close second |
Decision Tree | Moderate | Variance hurts ranking |
Gaussian NB | Good, weaker precision | |
Dummy | ~0.50 | Random baseline |
**Isolation Forest** | **~0.497** | **Worse than random (AUC < 0.5)** 

---

## ðŸŽ¯ Part C â€” Multi-Class Precision-Recall (OvR)

| Model | Avg Precision | Behavior |
|---|---|---|
KNN | ~0.93 | Best |
SVC | ~0.93 | Most stable |
Naive Bayes | ~0.82 | Precision drop |
Decision Tree | ~0.74 | Fit instability |
Dummy | ~0.18 | Random baseline |

---

## ðŸ§¾ Part D â€” Final Recommendation

| Metric | Best |
|---|---|
Accuracy | KNN / SVC |
Weighted-F1 | KNN / SVC |
ROC-AUC | SVC |
PR-AUC | KNN â‰ˆ SVC |

### âœ… Final Pick: **SVC**
- Highest ROC-AUC
- Excellent PR-AUC
- Stable across thresholds

KNN = strong runner-up

---

## â­ Brownie Points â€” Random Forest & XGBoost (Tuned Models)

| Model | Accuracy | Weighted-F1 |
|---|---|---|
Random Forest (tuned) | `0.9050` | `0.9046` |
**XGBoost (tuned)** | **`0.9075`** | **`0.9057`** |

### Ranking Among All Models

| Rank | Model |
|---|---|
ðŸ¥‡ | XGBoost (Tuned) |
ðŸ¥ˆ | SVC |
ðŸ¥‰ | KNN |
4ï¸âƒ£ | Random Forest (Tuned) |
---

## âŒ Additional Low-Performance Models (AUC < 0.5)

### ðŸ“‰ Isolation Forest

**Extracted Results**
- ROC-AUC: **â‰ˆ0.497**

**Interpretation**
- Performs **worse than random**
- Flags normal pixels as anomalies
- Not suitable since land-cover classes are not "outliers"

> ðŸ”´ Works for anomaly detection â€” not multi-class classification.

### ðŸ“‰ BernoulliNB

- Accuracy: `0.2305`
- Weighted-F1: `0.0864`
- AUC: **0.4937** (â‰ˆ random)

Fails due to binary-feature assumption on continuous data.

---

## ðŸ“Š Final Model Ranking

| Rank | Model |
|---|---|
1 | XGBoost (Tuned) |
2 | SVC |
3 | KNN |
4 | Random Forest (Tuned) |
5 | Logistic Regression |
6 | Gaussian NB |
7 | Decision Tree |
8 | **Isolation Forest & BernoulliNB (AUC < 0.5)** |
9 | Dummy baseline |

---

## âœ… Key Takeaways

- PRC more informative under imbalance
- AUC < 0.5 signals inverted scoring
- SVC best baseline
- XGBoost best tuned model

---
